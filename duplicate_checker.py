#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡å¤æ£€æŸ¥æ¨¡å—
ç”¨äºåœ¨æ·»åŠ æ–°æ¯”èµ›å‰æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæˆ–ç›¸ä¼¼çš„æ¯”èµ›
"""

import re
import json
import requests
from difflib import SequenceMatcher
from feishu_api import get_all_records
from config import DEEPSEEK_API_KEY, REQUEST_CONFIG
from typing import List, Dict, Tuple, Optional

class DuplicateChecker:
    """é‡å¤æ£€æŸ¥å™¨ç±»"""
    
    def __init__(self, similarity_threshold: float = 0.8):
        """
        åˆå§‹åŒ–é‡å¤æ£€æŸ¥å™¨
        
        Args:
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºæ˜¯é‡å¤
        """
        self.similarity_threshold = similarity_threshold
        self.existing_records = []
        self.load_existing_records()
    
    def load_existing_records(self):
        """åŠ è½½ç°æœ‰è®°å½•"""
        print("ğŸ”„ åŠ è½½ç°æœ‰è®°å½•...")
        records = get_all_records()
        if records:
            self.existing_records = records
            print(f"âœ… å·²åŠ è½½ {len(records)} æ¡ç°æœ‰è®°å½•")
        else:
            print("âš ï¸ æœªèƒ½åŠ è½½ç°æœ‰è®°å½•")
    
    def normalize_title(self, title: str) -> str:
        """æ ‡å‡†åŒ–æ ‡é¢˜ï¼Œç”¨äºæ¯”è¾ƒ"""
        if not title:
            return ""
        
        # è½¬æ¢ä¸ºå°å†™
        title = title.lower()
        
        # ç§»é™¤å¸¸è§çš„æ ‡ç‚¹ç¬¦å·å’Œç©ºç™½å­—ç¬¦
        title = re.sub(r'[\s\-_â€”â€“]+', '', title)
        
        # ç§»é™¤å¸¸è§çš„åç¼€è¯æ±‡
        suffixes = ['æ¯”èµ›', 'ç«èµ›', 'å¤§èµ›', 'competition', 'contest', 'challenge', 'hackathon']
        for suffix in suffixes:
            title = title.replace(suffix.lower(), '')
        
        return title.strip()
    
    def calculate_similarity(self, title1: str, title2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ ‡é¢˜çš„ç›¸ä¼¼åº¦"""
        norm_title1 = self.normalize_title(title1)
        norm_title2 = self.normalize_title(title2)
        
        if not norm_title1 or not norm_title2:
            return 0.0
        
        return SequenceMatcher(None, norm_title1, norm_title2).ratio()
    
    def analyze_duplicate_with_deepseek(self, new_title: str, new_description: str, existing_records: List[Dict]) -> Dict:
        """ä½¿ç”¨DeepSeek AIåˆ†ææ¯”èµ›é‡å¤æ€§
        
        Args:
            new_title: æ–°æ¯”èµ›æ ‡é¢˜
            new_description: æ–°æ¯”èµ›æè¿°
            existing_records: ç°æœ‰è®°å½•åˆ—è¡¨
        
        Returns:
            dict: AIåˆ†æç»“æœ
        """
        if not DEEPSEEK_API_KEY:
            print("âš ï¸ DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡AIé‡å¤åˆ†æ")
            return {'is_duplicate': False, 'confidence': 0.0, 'reason': 'APIæœªé…ç½®'}
        
        try:
            # æ„å»ºç°æœ‰æ¯”èµ›ä¿¡æ¯æ‘˜è¦
            existing_summaries = []
            for record in existing_records[:10]:  # é™åˆ¶æ•°é‡é¿å…tokenè¿‡å¤š
                fields = record.get('fields', {})
                title = fields.get('æ¯”èµ›åç§°', '')
                desc = fields.get('æ¯”èµ›æè¿°', '')
                if title:
                    existing_summaries.append(f"æ ‡é¢˜: {title}\næè¿°: {desc[:100]}...")
            
            existing_text = "\n\n".join(existing_summaries)
            
            prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ–°æ¯”èµ›æ˜¯å¦ä¸ç°æœ‰æ¯”èµ›é‡å¤ã€‚è¯·è€ƒè™‘æ¯”èµ›çš„ä¸»é¢˜ã€å†…å®¹ã€ç»„ç»‡æ–¹ç­‰å› ç´ ã€‚

æ–°æ¯”èµ›ä¿¡æ¯ï¼š
æ ‡é¢˜: {new_title}
æè¿°: {new_description}

ç°æœ‰æ¯”èµ›ä¿¡æ¯ï¼š
{existing_text}

è¯·è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼š
{{
  "is_duplicate": true/false,
  "confidence": 0.0-1.0,
  "most_similar_title": "æœ€ç›¸ä¼¼çš„æ¯”èµ›æ ‡é¢˜",
  "reason": "åˆ¤æ–­ç†ç”±"
}}

åˆ¤æ–­æ ‡å‡†ï¼š
- å¦‚æœæ¯”èµ›ä¸»é¢˜ã€å†…å®¹ã€æ—¶é—´å®Œå…¨ç›¸åŒï¼Œåˆ™ä¸ºé‡å¤
- å¦‚æœåªæ˜¯åç§°ç›¸ä¼¼ä½†å†…å®¹ä¸åŒï¼Œåˆ™ä¸é‡å¤
- è€ƒè™‘æ¯”èµ›çš„å…·ä½“é¢†åŸŸå’Œè¦æ±‚
"""
            
            headers = {
                'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'deepseek-chat',
                'messages': [
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'temperature': 0.1,
                'max_tokens': 800
            }
            
            response = requests.post(
                'https://api.deepseek.com/chat/completions',
                headers=headers,
                json=data,
                timeout=REQUEST_CONFIG['timeout']
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                try:
                    analysis = json.loads(content)
                    print(f"ğŸ¤– AIé‡å¤åˆ†æ: {analysis.get('reason', 'æ— ç†ç”±')}")
                    return analysis
                except json.JSONDecodeError:
                    print(f"âš ï¸ AIå“åº”è§£æå¤±è´¥: {content}")
                    return {'is_duplicate': False, 'confidence': 0.0, 'reason': 'è§£æå¤±è´¥'}
            else:
                print(f"âŒ DeepSeek APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return {'is_duplicate': False, 'confidence': 0.0, 'reason': 'APIè°ƒç”¨å¤±è´¥'}
                
        except Exception as e:
            print(f"âŒ DeepSeeké‡å¤åˆ†æå‡ºé”™: {str(e)}")
            return {'is_duplicate': False, 'confidence': 0.0, 'reason': f'åˆ†æå‡ºé”™: {str(e)}'}
    
    def check_exact_duplicate(self, title: str, platform: str = None) -> Optional[Dict]:
        """æ£€æŸ¥å®Œå…¨é‡å¤çš„è®°å½•"""
        for record in self.existing_records:
            fields = record.get('fields', {})
            existing_title = fields.get('æ ‡é¢˜', '')
            existing_platform = fields.get('å¹³å°', '')
            
            # å®Œå…¨åŒ¹é…æ ‡é¢˜
            if existing_title == title:
                # å¦‚æœæŒ‡å®šäº†å¹³å°ï¼Œä¹Ÿè¦åŒ¹é…å¹³å°
                if platform is None or existing_platform == platform:
                    return {
                        'type': 'exact',
                        'record': record,
                        'similarity': 1.0,
                        'existing_title': existing_title,
                        'existing_platform': existing_platform
                    }
        
        return None
    
    def check_similar_duplicate(self, title: str, platform: str = None) -> List[Dict]:
        """æ£€æŸ¥ç›¸ä¼¼çš„é‡å¤è®°å½•"""
        similar_records = []
        
        for record in self.existing_records:
            fields = record.get('fields', {})
            existing_title = fields.get('æ ‡é¢˜', '')
            existing_platform = fields.get('å¹³å°', '')
            
            if not existing_title:
                continue
            
            similarity = self.calculate_similarity(title, existing_title)
            
            if similarity >= self.similarity_threshold:
                # å¦‚æœæŒ‡å®šäº†å¹³å°ï¼Œä¼˜å…ˆè€ƒè™‘åŒå¹³å°çš„è®°å½•
                platform_match = platform is None or existing_platform == platform
                
                similar_records.append({
                    'type': 'similar',
                    'record': record,
                    'similarity': similarity,
                    'existing_title': existing_title,
                    'existing_platform': existing_platform,
                    'platform_match': platform_match
                })
        
        # æŒ‰ç›¸ä¼¼åº¦å’Œå¹³å°åŒ¹é…æ’åº
        similar_records.sort(key=lambda x: (x['platform_match'], x['similarity']), reverse=True)
        
        return similar_records
    
    def check_duplicate(self, title: str, platform: str = None, link: str = None, description: str = "", use_ai: bool = True) -> Dict:
        """ç»¼åˆæ£€æŸ¥é‡å¤è®°å½•"""
        result = {
            'is_duplicate': False,
            'duplicate_type': None,
            'exact_match': None,
            'similar_matches': [],
            'ai_analysis': None,
            'recommendation': 'add'  # add, skip, review
        }
        
        # æ£€æŸ¥å®Œå…¨é‡å¤
        exact_match = self.check_exact_duplicate(title, platform)
        if exact_match:
            result['is_duplicate'] = True
            result['duplicate_type'] = 'exact'
            result['exact_match'] = exact_match
            result['recommendation'] = 'skip'
            return result
        
        # æ£€æŸ¥é“¾æ¥é‡å¤ï¼ˆå¦‚æœæä¾›äº†é“¾æ¥ï¼‰
        if link:
            for record in self.existing_records:
                fields = record.get('fields', {})
                existing_link = fields.get('æ¯”èµ›é“¾æ¥', {}).get('link', '') or fields.get('é“¾æ¥', '')
                if existing_link == link:
                    result['is_duplicate'] = True
                    result['duplicate_type'] = 'link'
                    result['exact_match'] = {
                        'type': 'link',
                        'record': record,
                        'similarity': 1.0,
                        'existing_title': fields.get('æ¯”èµ›åç§°', '') or fields.get('æ ‡é¢˜', ''),
                        'existing_platform': fields.get('å¹³å°', '')
                    }
                    result['recommendation'] = 'skip'
                    return result
        
        # æ£€æŸ¥ç›¸ä¼¼é‡å¤
        similar_matches = self.check_similar_duplicate(title, platform)
        if similar_matches:
            result['similar_matches'] = similar_matches
            
            # å¦‚æœæœ‰é«˜ç›¸ä¼¼åº¦çš„åŒ¹é…ï¼Œå»ºè®®å®¡æŸ¥
            if similar_matches[0]['similarity'] >= 0.9:
                result['is_duplicate'] = True
                result['duplicate_type'] = 'similar'
                result['recommendation'] = 'review'
        
        # ä½¿ç”¨DeepSeek AIè¿›è¡Œæ™ºèƒ½é‡å¤åˆ†æ
        if use_ai and description and DEEPSEEK_API_KEY:
            print(f"ğŸ¤– ä½¿ç”¨AIåˆ†ææ¯”èµ›é‡å¤æ€§: {title}")
            ai_analysis = self.analyze_duplicate_with_deepseek(title, description, self.existing_records)
            result['ai_analysis'] = ai_analysis
            
            # å¦‚æœAIåˆ¤æ–­ä¸ºé‡å¤ä¸”ç½®ä¿¡åº¦é«˜ï¼Œæ›´æ–°ç»“æœ
            if ai_analysis.get('is_duplicate') and ai_analysis.get('confidence', 0) >= 0.8:
                result['is_duplicate'] = True
                result['duplicate_type'] = 'ai_detected'
                result['recommendation'] = 'skip' if ai_analysis.get('confidence', 0) >= 0.9 else 'review'
                print(f"ğŸš« AIæ£€æµ‹åˆ°é‡å¤: {ai_analysis.get('reason', 'æœªçŸ¥åŸå› ')}")
            elif ai_analysis.get('confidence', 0) >= 0.6:
                result['recommendation'] = 'review'
                print(f"âš ï¸ AIå»ºè®®äººå·¥å®¡æŸ¥: {ai_analysis.get('reason', 'æœªçŸ¥åŸå› ')}")
        
        return result
    
    def print_duplicate_report(self, title: str, platform: str, check_result: Dict):
        """æ‰“å°é‡å¤æ£€æŸ¥æŠ¥å‘Š"""
        if not check_result['is_duplicate']:
            ai_analysis = check_result.get('ai_analysis')
            if ai_analysis and ai_analysis.get('confidence', 0) > 0.3:
                print(f"âœ… æ— é‡å¤: {title} (AIç½®ä¿¡åº¦: {ai_analysis.get('confidence', 0):.2f})")
            else:
                print(f"âœ… æ— é‡å¤: {title}")
            return
        
        print(f"âš ï¸ å‘ç°é‡å¤: {title}")
        print(f"   å¹³å°: {platform}")
        print(f"   é‡å¤ç±»å‹: {check_result['duplicate_type']}")
        
        if check_result['exact_match']:
            match = check_result['exact_match']
            print(f"   å®Œå…¨åŒ¹é…: {match['existing_title']}")
            print(f"   ç°æœ‰å¹³å°: {match['existing_platform']}")
        
        if check_result['similar_matches']:
            print(f"   ç›¸ä¼¼åŒ¹é… ({len(check_result['similar_matches'])} æ¡):")
            for i, match in enumerate(check_result['similar_matches'][:3], 1):
                print(f"     {i}. {match['existing_title']} (ç›¸ä¼¼åº¦: {match['similarity']:.2f})")
                print(f"        å¹³å°: {match['existing_platform']}")
        
        # æ˜¾ç¤ºAIåˆ†æç»“æœ
        ai_analysis = check_result.get('ai_analysis')
        if ai_analysis:
            print(f"   ğŸ¤– AIåˆ†æ:")
            print(f"      é‡å¤åˆ¤æ–­: {'æ˜¯' if ai_analysis.get('is_duplicate') else 'å¦'}")
            print(f"      ç½®ä¿¡åº¦: {ai_analysis.get('confidence', 0):.2f}")
            print(f"      ç†ç”±: {ai_analysis.get('reason', 'æ— ')}")
            if ai_analysis.get('most_similar_title'):
                print(f"      æœ€ç›¸ä¼¼: {ai_analysis.get('most_similar_title')}")
        
        print(f"   å»ºè®®: {check_result['recommendation']}")

def check_competition_duplicate(title: str, platform: str = None, link: str = None, 
                              description: str = "", similarity_threshold: float = 0.8, 
                              use_ai: bool = True) -> Dict:
    """æ£€æŸ¥æ¯”èµ›æ˜¯å¦é‡å¤çš„ä¾¿æ·å‡½æ•°"""
    checker = DuplicateChecker(similarity_threshold)
    return checker.check_duplicate(title, platform, link, description, use_ai)

def batch_check_duplicates(competitions: List[Dict], similarity_threshold: float = 0.8, use_ai: bool = True) -> List[Dict]:
    """æ‰¹é‡æ£€æŸ¥æ¯”èµ›é‡å¤"""
    checker = DuplicateChecker(similarity_threshold)
    results = []
    
    for comp in competitions:
        title = comp.get('title', '')
        platform = comp.get('platform', '')
        link = comp.get('link', '')
        description = comp.get('description', '')
        
        check_result = checker.check_duplicate(title, platform, link, description, use_ai)
        results.append({
            'competition': comp,
            'check_result': check_result
        })
    
    return results

if __name__ == "__main__":
    # æµ‹è¯•åŠŸèƒ½
    import argparse
    
    parser = argparse.ArgumentParser(description="é‡å¤æ£€æŸ¥å·¥å…·")
    parser.add_argument("--title", required=True, help="è¦æ£€æŸ¥çš„æ¯”èµ›æ ‡é¢˜")
    parser.add_argument("--platform", help="æ¯”èµ›å¹³å°")
    parser.add_argument("--link", help="æ¯”èµ›é“¾æ¥")
    parser.add_argument("--threshold", type=float, default=0.8, help="ç›¸ä¼¼åº¦é˜ˆå€¼")
    
    args = parser.parse_args()
    
    checker = DuplicateChecker(args.threshold)
    result = checker.check_duplicate(args.title, args.platform, args.link)
    checker.print_duplicate_report(args.title, args.platform or "æœªçŸ¥", result)