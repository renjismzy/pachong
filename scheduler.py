#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
æ¯å¤©æ—©ä¸Š9ç‚¹è‡ªåŠ¨çˆ¬å–æ‰€æœ‰å¹³å°çš„æ¯”èµ›ä¿¡æ¯
"""

import schedule
import time
import datetime
import logging
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥çˆ¬è™«æ¨¡å—
try:
    from crawlers.baidu_crawler import crawl_baidu
    from crawlers.aliyun_crawler import crawl_aliyun
    from crawlers.tencent_crawler import crawl_tencent
    from crawlers.wechat_crawler import crawl_wechat
    from feishu_api import update_all_competition_status
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# é…ç½®æ—¥å¿—
def setup_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = project_root / "logs"
    log_dir.mkdir(exist_ok=True)
    
    log_file = log_dir / f"scheduler_{datetime.datetime.now().strftime('%Y%m')}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

def run_daily_crawl():
    """æ‰§è¡Œæ¯æ—¥çˆ¬è™«ä»»åŠ¡"""
    start_time = datetime.datetime.now()
    logger.info("="*60)
    logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ¯æ—¥çˆ¬è™«ä»»åŠ¡ - {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("="*60)
    
    success_count = 0
    total_platforms = 4
    
    # çˆ¬å–ç™¾åº¦AI Studio
    try:
        logger.info("ğŸ“ å¼€å§‹çˆ¬å–ç™¾åº¦AI Studio...")
        crawl_baidu()
        success_count += 1
        logger.info("âœ… ç™¾åº¦AI Studioçˆ¬å–å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ ç™¾åº¦AI Studioçˆ¬å–å¤±è´¥: {str(e)}")
    
    # ç­‰å¾…é—´éš”ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
    time.sleep(5)
    
    # çˆ¬å–é˜¿é‡Œå¤©æ± 
    try:
        logger.info("ğŸ“ å¼€å§‹çˆ¬å–é˜¿é‡Œå¤©æ± ...")
        crawl_aliyun()
        success_count += 1
        logger.info("âœ… é˜¿é‡Œå¤©æ± çˆ¬å–å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ é˜¿é‡Œå¤©æ± çˆ¬å–å¤±è´¥: {str(e)}")
    
    # ç­‰å¾…é—´éš”
    time.sleep(5)
    
    # çˆ¬å–è…¾è®¯CSDN
    try:
        logger.info("ğŸ“ å¼€å§‹çˆ¬å–è…¾è®¯CSDN...")
        crawl_tencent()
        success_count += 1
        logger.info("âœ… è…¾è®¯CSDNçˆ¬å–å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ è…¾è®¯CSDNçˆ¬å–å¤±è´¥: {str(e)}")
    
    # ç­‰å¾…é—´éš”
    time.sleep(5)
    
    # çˆ¬å–å¾®ä¿¡å…¬ä¼—å·
    try:
        logger.info("ğŸ“ å¼€å§‹çˆ¬å–å¾®ä¿¡å…¬ä¼—å·...")
        crawl_wechat()
        success_count += 1
        logger.info("âœ… å¾®ä¿¡å…¬ä¼—å·çˆ¬å–å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ å¾®ä¿¡å…¬ä¼—å·çˆ¬å–å¤±è´¥: {str(e)}")
    
    # ç­‰å¾…é—´éš”
    time.sleep(5)
    
    # æ›´æ–°æ¯”èµ›çŠ¶æ€
    try:
        logger.info("ğŸ“ å¼€å§‹æ›´æ–°æ¯”èµ›çŠ¶æ€...")
        update_all_competition_status()
        logger.info("âœ… æ¯”èµ›çŠ¶æ€æ›´æ–°å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ æ¯”èµ›çŠ¶æ€æ›´æ–°å¤±è´¥: {str(e)}")
    
    # ä»»åŠ¡å®Œæˆç»Ÿè®¡
    end_time = datetime.datetime.now()
    duration = end_time - start_time
    
    logger.info("="*60)
    logger.info(f"ğŸ“Š ä»»åŠ¡æ‰§è¡Œå®Œæˆ - {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"â±ï¸ æ‰§è¡Œæ—¶é•¿: {duration}")
    logger.info(f"ğŸ“ˆ æˆåŠŸå¹³å°: {success_count}/{total_platforms}")
    if success_count == total_platforms:
        logger.info("ğŸ‰ æ‰€æœ‰å¹³å°çˆ¬å–æˆåŠŸï¼")
    else:
        logger.warning(f"âš ï¸ æœ‰ {total_platforms - success_count} ä¸ªå¹³å°çˆ¬å–å¤±è´¥")
    logger.info("="*60)

def run_scheduler():
    """è¿è¡Œå®šæ—¶è°ƒåº¦å™¨"""
    logger.info("ğŸ•˜ å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å¯åŠ¨")
    logger.info("ğŸ“… è®¡åˆ’ä»»åŠ¡: æ¯å¤©æ—©ä¸Š9:00æ‰§è¡Œçˆ¬è™«ä»»åŠ¡")
    
    # è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼šæ¯å¤©æ—©ä¸Š9ç‚¹æ‰§è¡Œ
    schedule.every().day.at("09:00").do(run_daily_crawl)
    
    # å¯é€‰ï¼šæ·»åŠ æµ‹è¯•ä»»åŠ¡ï¼ˆæ¯åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼Œç”¨äºæµ‹è¯•ï¼‰
    # schedule.every().minute.do(run_daily_crawl)
    
    logger.info("â° ç­‰å¾…å®šæ—¶ä»»åŠ¡è§¦å‘...")
    
    while True:
        try:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        except KeyboardInterrupt:
            logger.info("\nğŸ‘‹ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢è°ƒåº¦å™¨...")
            break
        except Exception as e:
            logger.error(f"âŒ è°ƒåº¦å™¨è¿è¡Œå‡ºé”™: {str(e)}")
            time.sleep(60)

def run_once():
    """ç«‹å³æ‰§è¡Œä¸€æ¬¡çˆ¬è™«ä»»åŠ¡ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    logger.info("ğŸ§ª ç«‹å³æ‰§è¡Œçˆ¬è™«ä»»åŠ¡ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
    run_daily_crawl()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æ¯”èµ›ä¿¡æ¯çˆ¬è™«å®šæ—¶è°ƒåº¦å™¨")
    parser.add_argument(
        "--mode", 
        choices=["schedule", "once"], 
        default="schedule",
        help="è¿è¡Œæ¨¡å¼: schedule(å®šæ—¶è°ƒåº¦) æˆ– once(ç«‹å³æ‰§è¡Œ)"
    )
    
    args = parser.parse_args()
    
    try:
        if args.mode == "once":
            run_once()
        else:
            run_scheduler()
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºè¿è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)